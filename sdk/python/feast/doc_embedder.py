import os
from pathlib import Path
from typing import Optional, Protocol, runtime_checkable

import pandas as pd

from feast.chunker import BaseChunker, TextChunker
from feast.embedder import BaseEmbedder, MultiModalEmbedder
from feast.feature_store import FeatureStore
from feast.repo_config import load_repo_config
from feast.repo_operations import apply_total


@runtime_checkable
class LogicalLayerFn(Protocol):
    """
    Protocol defining the structure for logical layer functions.

    The logical layer transforms the output of Chunker + Embedder
    into the format expected by the FeatureView schema.
    """

    def __call__(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Transform chunked + embedded DataFrame to FeatureView schema.

        Args:
            df: Input DataFrame with chunks and embeddings.

        Returns:
            DataFrame with columns matching FeatureView schema.
        """
        ...


def default_logical_layer_fn(df: pd.DataFrame) -> pd.DataFrame:
    """
    Default logical layer function that transforms the output of Chunker + Embedder
    into the format expected by the FeatureView schema.
    """
    from datetime import datetime, timezone

    return pd.DataFrame(
        {
            "passage_id": df["chunk_id"],
            "text": df["text"],
            "embedding": df["text_embedding"],
            "event_timestamp": [datetime.now(timezone.utc)] * len(df),
            "source_id": df["original_id"],
        }
    )


def generate_repo_file(
    repo_path: str, feature_view_name: str = "text_feature_view"
) -> str:
    """
    Generate a Python file with Entity and FeatureView definitions.

    This file is compatible with `feast apply` CLI.

    Returns:
        Path to generated file.
    """
    import os

    code = f'''"""
Auto-generated by DocEmbedder.
Compatible with `feast apply` CLI.
"""
from datetime import timedelta

from feast import Entity, FeatureView, Field, FileSource
from feast.types import Array, Float32, String, ValueType


# Entity
text_entity = Entity(
    name="passage_id",
    join_keys=["passage_id"],
    description="Passage identifier",
    value_type=ValueType.STRING,
)

# Source
{feature_view_name}_source = FileSource(
    name="{feature_view_name}_source",
    path="data/{feature_view_name}.parquet",
    timestamp_field="event_timestamp",
)

# FeatureView
{feature_view_name} = FeatureView(
    name="{feature_view_name}",
    entities=[text_entity],
    ttl=timedelta(days=1),
    schema=[
        Field(
            name="text",
            dtype=String,
            description="Document text content",
        ),
        Field(
            name="embedding",
            dtype=Array(Float32),
            description="Vector embedding",
            vector_index=True,
            vector_length=384,
            vector_search_metric="COSINE",
        ),
        Field(
            name="source_id",
            dtype=String,
            description="Source ID",
        ),
    ],
    source={feature_view_name}_source,
    online=True,
)
'''

    filepath = os.path.join(repo_path, feature_view_name + ".py")
    with open(filepath, "w") as f:
        f.write(code)

    return filepath


class DocEmbedder:
    """
    DocEmbedder is a class that embeds documents and chunks them into a format expected by the FeatureView schema using a Logic Implementation By the user.

    Args:
        repo_path: Path to the feature repo (can be "." for current directory).
        yaml_file: Name of the feature_store.yaml file inside repo_path.
            Defaults to "feature_store.yaml".
        feature_view_name: Name of the feature view to create.
        chunker: Chunker to use for chunking the documents.
        embedder: Embedder to use for embedding the documents.
        logical_layer_fn: Logical layer function to use for transforming the output of the chunker and embedder into the format expected by the FeatureView schema.
        create_feature_view: Whether to create a feature view in the feature repo By default it will generate a Python file with the FeatureView definition.
    """

    def __init__(
        self,
        repo_path: str,
        yaml_file: str = "feature_store.yaml",
        feature_view_name: str = "text_feature_view",
        chunker: BaseChunker = TextChunker(),
        embedder: BaseEmbedder = MultiModalEmbedder(),
        logical_layer_fn: LogicalLayerFn = default_logical_layer_fn,
        create_feature_view: bool = True,
    ):
        self.repo_path = repo_path
        self.yaml_path = os.path.join(Path(repo_path).resolve(), yaml_file)
        self.feature_view_name = feature_view_name
        self.chunker = chunker
        self.embedder = embedder
        if isinstance(logical_layer_fn, LogicalLayerFn):
            self.logical_layer_fn = logical_layer_fn
        else:
            raise ValueError(
                "logical_layer_fn must be a LogicalLayerFn or a function that takes a DataFrame and returns a DataFrame"
            )
        if create_feature_view:
            generate_repo_file(repo_path=repo_path, feature_view_name=feature_view_name)
            self.apply_repo()

    def save_to_online_store(self, df: pd.DataFrame, feature_view_name: str) -> None:
        """
        Save the embedded documents to the online store.
        """
        print(f"OS {os.getcwd()}")
        store = FeatureStore(repo_path=self.repo_path)
        store.write_to_online_store(
            feature_view_name=feature_view_name,
            df=df,
        )

    # TODO (Future scope): Implement save_to_offline_store to write embedded
    # documents to the offline store. Currently blocked by DaskOfflineStore
    # .offline_write_batch not creating the parquet file if it does not exist.
    # Once that is fixed, add a method that calls:
    #   store = FeatureStore(repo_path=self.repo_path)
    #   store.write_to_offline_store(feature_view_name=feature_view_name, df=df)

    def apply_repo(self) -> None:
        """
        Apply the repository to register feature views in the registry.
        """
        original_cwd = os.getcwd()
        repo_path = Path(self.repo_path).resolve()
        config = load_repo_config(
            repo_path=repo_path,
            fs_yaml_file=Path(self.yaml_path),
        )
        apply_total(
            repo_config=config,
            repo_path=repo_path,
            skip_source_validation=True,
        )
        # Restore CWD since apply_total changes it via os.chdir
        os.chdir(original_cwd)

    def embed_documents(
        self,
        documents: pd.DataFrame,
        id_column: str,
        source_column: str,
        type_column: Optional[str] = None,
        column_mapping: Optional[dict[str, tuple[str, str]]] = None,
    ) -> pd.DataFrame:
        """
        Embed a list of documents and chunk them into a format expected by the FeatureView schema using a Logic Implementation By the user and save the DataFrame to the online store.

        Args:
            documents: DataFrame containing the documents to embed.
            id_column: Column name containing the document IDs.
            source_column: Column name containing the document sources.
            type_column: Column name containing the document types.
            column_mapping: Dictionary mapping source columns to (modality, output column).

        Returns:
            DataFrame with the embedded documents.

        Example:
            documents = pd.DataFrame({
                "id": [1, 2, 3],
                "source": ["source1", "source2", "source3"],
                "type": ["type1", "type2", "type3"],
                "text": ["text1", "text2", "text3"],
            })
            column_mapping = {
                "text": ("text", "text_embedding"),
            }
            df = embed_documents(documents=documents, id_column="id", source_column="source", type_column="type", column_mapping=column_mapping)

        """
        df = self.chunker.chunk_dataframe(
            df=documents,
            id_column=id_column,
            source_column=source_column,
            type_column=type_column,
        )
        if column_mapping is None:
            column_mapping = {"text": ("text", "text_embedding")}
        df = self.embedder.embed_dataframe(df, column_mapping=column_mapping)

        df = self.logical_layer_fn(df)

        self.save_to_online_store(df=df, feature_view_name=self.feature_view_name)
        return df
